{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sought-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import urllib\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "from socket import timeout\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc\n",
    "import pickle\n",
    "import gameOfLife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proved-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dangerous-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") #Подрубайтунг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "resident-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"gl/\" #да да там\n",
    "size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clean-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveState(data, name, epoch):\n",
    "    with open('gl/'+str(name)+\"_\"+str(epoch)+\".gl\", 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "def readState(name, epoch):\n",
    "    with open('gl/'+str(name)+\"_\"+str(epoch)+\".gl\", 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def showGame(result, delay = 45):\n",
    "    exit = False\n",
    "    while not exit:\n",
    "        for i in range(len(result)):\n",
    "            img = np.zeros([size, size, 3], dtype=float)\n",
    "            img[:,:,0] = result[i]*0.1\n",
    "            img[:,:,1] = result[i]*0.4\n",
    "            img[:,:,2] = result[i]*0.9\n",
    "\n",
    "            #vis2 = cv2.cvtColor(result[i].astype(np.float32), cv2.COLOR_GRAY2BGR)\n",
    "            resized = cv2.resize(img, (600, 600), 0, 0, interpolation = cv2.INTER_NEAREST)\n",
    "            cv2.imshow(\"game\", resized)\n",
    "            key = cv2.waitKey(delay) \n",
    "            if key!=-1:\n",
    "                exit = True\n",
    "                break\n",
    "\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "agreed-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameOfLifeDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.transform = transform\n",
    "        self.folder = folder\n",
    "        \n",
    "        files = os.listdir(self.folder)\n",
    "        \n",
    "        self.count = len(files)\n",
    "        self.games_path = list()\n",
    "        \n",
    "        for f in os.listdir(self.folder):\n",
    "            self.games_path.append(f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.count\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.games_path[index]\n",
    "        game, epoch = path.split('.')[0].split('_')\n",
    "        \n",
    "        cur_step = readState(game, epoch)\n",
    "        next_step = gameOfLife.computeStep(cur_step)\n",
    "        if self.transform is not None:\n",
    "            cur_step = self.transform(cur_step)\n",
    "            next_step = self.transform(next_step)\n",
    "\n",
    "        return cur_step, next_step, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "freelance-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = GameOfLifeDataset(train_folder, transform=transforms.Compose([transforms.ToTensor(),]))\n",
    "#showGame([ds[1][0]])\n",
    "train_dataset = GameOfLifeDataset(train_folder, transform=transforms.Compose([transforms.ToTensor(),]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "numerical-richards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "data_size = len(train_dataset)\n",
    "print(data_size)\n",
    "validation_fraction = .2\n",
    "\n",
    "\n",
    "val_split = int(np.floor((validation_fraction) * data_size))\n",
    "indices = list(range(data_size))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_indices, train_indices = indices[:val_split], indices[val_split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                         sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "typical-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(loss_history):\n",
    "    fig, axs = plt.subplots(1)\n",
    "    fig.set_size_inches(12, 7)\n",
    "\n",
    "    axs[0].plot(loss_history, label = \"loss\")\n",
    "    axs[0].grid()\n",
    "    axs[0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "labeled-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_loss(pred, target, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "\n",
    "    intersection = (pred * target).sum(dim=0).sum(dim=0)\n",
    "\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=0).sum(dim=0) + target.sum(dim=0).sum(dim=0) + smooth)))\n",
    "\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "municipal-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def compute_accuracy(model, loader, device):\n",
    "    \"\"\"\n",
    "    Computes accuracy on the dataset wrapped in a loader\n",
    "\n",
    "    Returns: accuracy as a float value between 0 and 1\n",
    "    \"\"\"\n",
    "    model.eval()  # Evaluation mode\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i_step, (x, y, _) in enumerate(loader):\n",
    "            x, y = x.float(), y.float()\n",
    "            prediction = model(x.to(device)).cpu()\n",
    "            #print(prediction.shape)\n",
    "\n",
    "            for i in range(x.shape[0]):\n",
    "                for j in range(x.shape[1]):\n",
    "                    y_data = y[i][j]\n",
    "                    pred_data = np.around(prediction[i][j])\n",
    "                    countMap = map(lambda x, y: 1 if x==y else 0, y_data.reshape(-1), pred_data.reshape(-1))\n",
    "                    #print(pred_data)\n",
    "\n",
    "                    correct += sum(list(countMap))/(y_data.shape[0]*y_data.shape[1])\n",
    "                    total += 1\n",
    "                    \n",
    "            del prediction\n",
    "    \n",
    "    return float(correct)/total\n",
    "\n",
    "def train_model_v2(model, train_loader, val_loader, loss, optimizer, num_epochs, scheduler = None):    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for i_step, (x, y,_) in enumerate(train_loader):\n",
    "            x=x.float()\n",
    "            y=y.float()\n",
    "            x_gpu = x.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            prediction = model(x_gpu)    \n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            for i in range(x.shape[0]):\n",
    "                for j in range(x.shape[1]):\n",
    "                    y_data = y[i][j]\n",
    "                    pred_data = np.around(prediction.cpu().detach().numpy()[i][j])\n",
    "                    countMap = map(lambda x, y: 1 if x==y else 0, y_data.reshape(-1), pred_data.reshape(-1))\n",
    "                    #print(pred_data)\n",
    "\n",
    "                    correct_samples += sum(list(countMap))/(y_data.shape[0]*y_data.shape[1])\n",
    "                    total_samples += 1\n",
    "            \n",
    "            #_, indices = torch.max(prediction, 1)\n",
    "            #correct_samples += torch.sum(indices == y_gpu)\n",
    "            #total_samples += y.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "\n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader, device)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(ave_loss)\n",
    "            \n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n",
    "        \n",
    "    return loss_history, train_history, val_history\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "national-process",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1, 1, 3, padding=1),\n",
    ")\n",
    "nn_model.type(torch.cuda.FloatTensor)\n",
    "nn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fleet-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.SGD(nn_model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "retained-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheduler = optim.lr_scheduler.StepLR(optimizer , step_size=2, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "economic-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\neo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.238309, Train accuracy: 0.846910, Val accuracy: 0.860556\n",
      "Average loss: 0.184533, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.157154, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.164347, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.171776, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.163419, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.149991, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.148773, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.156111, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.143916, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.143918, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.152489, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.145084, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.141395, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.142218, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.135503, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.136591, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.134813, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.132482, Train accuracy: 0.860833, Val accuracy: 0.860556\n",
      "Average loss: 0.136735, Train accuracy: 0.860833, Val accuracy: 0.860556\n"
     ]
    }
   ],
   "source": [
    "loss_history, train_history, val_history = train_model_v2(nn_model, train_loader, val_loader, loss, optimizer, 20, sheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "governmental-holly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 30, 30])\n",
      "torch.Size([10, 1, 30, 30])\n",
      "torch.Size([10, 1, 30, 30])\n",
      "torch.Size([2, 1, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "for i_step, (x, y,_) in enumerate(train_loader):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sharp-assignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "for i_step, (x, y,_) in enumerate(val_loader):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-twelve",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
