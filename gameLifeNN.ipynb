{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "sought-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import urllib\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "from socket import timeout\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc\n",
    "import pickle\n",
    "import gameOfLife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "proved-norman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "dangerous-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") #Подрубайтунг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "resident-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"gl/\" #да да там\n",
    "size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveState(data, name, epoch):\n",
    "    with open('gl/'+str(name)+\"_\"+str(epoch)+\".gl\", 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "def readState(name, epoch):\n",
    "    with open('gl/'+str(name)+\"_\"+str(epoch)+\".gl\", 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def showGame(result, delay = 45):\n",
    "    exit = False\n",
    "    while not exit:\n",
    "        for i in range(len(result)):\n",
    "            img = np.zeros([size, size, 3], dtype=float)\n",
    "            img[:,:,0] = result[i]*0.1\n",
    "            img[:,:,1] = result[i]*0.4\n",
    "            img[:,:,2] = result[i]*0.9\n",
    "\n",
    "            #vis2 = cv2.cvtColor(result[i].astype(np.float32), cv2.COLOR_GRAY2BGR)\n",
    "            resized = cv2.resize(img, (600, 600), 0, 0, interpolation = cv2.INTER_NEAREST)\n",
    "            cv2.imshow(\"game\", resized)\n",
    "            key = cv2.waitKey(delay) \n",
    "            if key!=-1:\n",
    "                exit = True\n",
    "                break\n",
    "\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameOfLifeDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.transform = transform\n",
    "        self.folder = folder\n",
    "        \n",
    "        files = os.listdir(self.folder)\n",
    "        \n",
    "        self.count = len(files)\n",
    "        self.games_path = list()\n",
    "        \n",
    "        for f in os.listdir(self.folder):\n",
    "            self.games_path.append(f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.count\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.games_path[index]\n",
    "        game, epoch = path.split('.')[0].split('_')\n",
    "        \n",
    "        cur_step = readState(game, epoch)\n",
    "        next_step = gameOfLife.computeStep(cur_step)\n",
    "        if self.transform is not None:\n",
    "            cur_step = self.transform(cur_step)\n",
    "            next_step = self.transform(next_step)\n",
    "\n",
    "        return cur_step, next_step, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = GameOfLifeDataset(train_folder, transform=transforms.Compose([transforms.ToTensor(),]))\n",
    "#showGame([ds[1][0]])\n",
    "train_dataset = GameOfLifeDataset(train_folder, transform=transforms.Compose([transforms.ToTensor(),]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "data_size = len(train_dataset)\n",
    "print(data_size)\n",
    "validation_fraction = .2\n",
    "\n",
    "\n",
    "val_split = int(np.floor((validation_fraction) * data_size))\n",
    "indices = list(range(data_size))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_indices, train_indices = indices[:val_split], indices[val_split:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                         sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(loss_history):\n",
    "    fig, axs = plt.subplots(1)\n",
    "    fig.set_size_inches(12, 7)\n",
    "\n",
    "    axs[0].plot(loss_history, label = \"loss\")\n",
    "    axs[0].grid()\n",
    "    axs[0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_loss(pred, target, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "\n",
    "    intersection = (pred * target).sum(dim=0).sum(dim=0)\n",
    "\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=0).sum(dim=0) + target.sum(dim=0).sum(dim=0) + smooth)))\n",
    "\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def compute_accuracy(model, loader, device):\n",
    "    \"\"\"\n",
    "    Computes accuracy on the dataset wrapped in a loader\n",
    "\n",
    "    Returns: accuracy as a float value between 0 and 1\n",
    "    \"\"\"\n",
    "    model.eval()  # Evaluation mode\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i_step, (x, y, _) in enumerate(loader):\n",
    "            x, y = x.float(), y.float()\n",
    "            prediction = model(x.to(device)).cpu()\n",
    "            #print(prediction.shape)\n",
    "\n",
    "            for i in range(x.shape[0]):\n",
    "                for j in range(x.shape[1]):\n",
    "                    y_data = y[i][j]\n",
    "                    pred_data = np.around(prediction[i][j])\n",
    "                    countMap = map(lambda x, y: 1 if x==y else 0, y_data.reshape(-1), pred_data.reshape(-1))\n",
    "                    #print(pred_data)\n",
    "\n",
    "                    correct += sum(list(countMap))/(y_data.shape[0]*y_data.shape[1])\n",
    "                    total += 1\n",
    "                    \n",
    "            del prediction\n",
    "    \n",
    "    return float(correct)/total\n",
    "\n",
    "def train_model_v2(model, train_loader, val_loader, loss, optimizer, num_epochs, scheduler = None):    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for i_step, (x, y,_) in enumerate(train_loader):\n",
    "            x=x.float()\n",
    "            y=y.float()\n",
    "            x_gpu = x.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            prediction = model(x_gpu)    \n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            for i in range(x.shape[0]):\n",
    "                for j in range(x.shape[1]):\n",
    "                    y_data = y[i][j]\n",
    "                    pred_data = np.around(prediction.cpu().detach().numpy()[i][j])\n",
    "                    countMap = map(lambda x, y: 1 if x==y else 0, y_data.reshape(-1), pred_data.reshape(-1))\n",
    "                    #print(pred_data)\n",
    "\n",
    "                    correct_samples += sum(list(countMap))/(y_data.shape[0]*y_data.shape[1])\n",
    "                    total_samples += 1\n",
    "            \n",
    "            #_, indices = torch.max(prediction, 1)\n",
    "            #correct_samples += torch.sum(indices == y_gpu)\n",
    "            #total_samples += y.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "\n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader, device)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(ave_loss)\n",
    "            \n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n",
    "        \n",
    "    return loss_history, train_history, val_history\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(1, 1, 3, padding=1),\n",
    ")\n",
    "nn_model.type(torch.cuda.FloatTensor)\n",
    "nn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.SGD(nn_model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheduler = optim.lr_scheduler.StepLR(optimizer , step_size=2, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history, train_history, val_history = train_model_v2(nn_model, train_loader, val_loader, loss, optimizer, 20, sheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_step, (x, y,_) in enumerate(train_loader):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "sharp-assignment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "for i_step, (x, y,_) in enumerate(val_loader):\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-twelve",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
